{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282fd949",
   "metadata": {
    "papermill": {
     "duration": 0.00368,
     "end_time": "2025-07-28T07:55:06.741074",
     "exception": false,
     "start_time": "2025-07-28T07:55:06.737394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note: Changes from original notebook: remove Sentence Transformer model, only use LLMs for final result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f42ccd",
   "metadata": {
    "papermill": {
     "duration": 0.002993,
     "end_time": "2025-07-28T07:55:06.747519",
     "exception": false,
     "start_time": "2025-07-28T07:55:06.744526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466d9560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:55:06.754851Z",
     "iopub.status.busy": "2025-07-28T07:55:06.754552Z",
     "iopub.status.idle": "2025-07-28T07:55:53.505419Z",
     "shell.execute_reply": "2025-07-28T07:55:53.504440Z"
    },
    "papermill": {
     "duration": 46.760241,
     "end_time": "2025-07-28T07:55:53.510907",
     "exception": false,
     "start_time": "2025-07-28T07:55:06.750666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.2.0) (3.13.1)\r\n",
      "Installing collected packages: triton\r\n",
      "Successfully installed triton-2.2.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6c8943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:55:53.519808Z",
     "iopub.status.busy": "2025-07-28T07:55:53.519089Z",
     "iopub.status.idle": "2025-07-28T07:56:42.590828Z",
     "shell.execute_reply": "2025-07-28T07:56:42.589783Z"
    },
    "papermill": {
     "duration": 49.082134,
     "end_time": "2025-07-28T07:56:42.596621",
     "exception": false,
     "start_time": "2025-07-28T07:55:53.514487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl\r\n",
      "Requirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (2024.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->xformers==0.0.24042abc8.d20240802) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.3.0)\r\n",
      "Installing collected packages: xformers\r\n",
      "Successfully installed xformers-0.0.24+042abc8.d20240802\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e476a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:56:42.605904Z",
     "iopub.status.busy": "2025-07-28T07:56:42.605273Z",
     "iopub.status.idle": "2025-07-28T07:56:43.670460Z",
     "shell.execute_reply": "2025-07-28T07:56:43.669523Z"
    },
    "papermill": {
     "duration": 1.071904,
     "end_time": "2025-07-28T07:56:43.672374",
     "exception": false,
     "start_time": "2025-07-28T07:56:42.600470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/lmsys-modules-0805 human_pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaaba4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:56:43.681737Z",
     "iopub.status.busy": "2025-07-28T07:56:43.681143Z",
     "iopub.status.idle": "2025-07-28T07:56:44.024214Z",
     "shell.execute_reply": "2025-07-28T07:56:44.023178Z"
    },
    "papermill": {
     "duration": 0.349397,
     "end_time": "2025-07-28T07:56:44.025804",
     "exception": false,
     "start_time": "2025-07-28T07:56:43.676407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lmsys-checkpoints-0-0805/model.safetensors.index.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00003-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/config.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00001-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/tokenizer.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/tokenizer_config.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00004-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/special_tokens_map.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00002-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/tokenizer.model\n",
      "/kaggle/input/lmsys-modules-0805/utils.py\n",
      "/kaggle/input/lmsys-modules-0805/models/modeling_gemma2.py\n",
      "/kaggle/input/lmsys-modules-0805/models/modeling_llama.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/triton_utils.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/rms_norm.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/flash_attention_nopad.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/fused_rotary_emb.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/gelu_and_mul.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/silu_and_mul.py\n",
      "/kaggle/input/lmsys-modules-0805/data/collators.py\n",
      "/kaggle/input/lmsys-modules-0805/data/dataset.py\n",
      "/kaggle/input/lmsys-modules-0805/data/processors.py\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model.safetensors.index.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00003-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/config.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00001-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/tokenizer.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/tokenizer_config.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00004-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/special_tokens_map.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00002-of-00004.safetensors\n",
      "/kaggle/input/some-pack/balanced_transformed_dataset.csv\n",
      "/kaggle/input/some-pack/faiss_cpu_downloads/faiss_cpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence-transformer-model/config.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/README.md\n",
      "/kaggle/input/some-pack/sentence-transformer-model/tokenizer.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/tokenizer_config.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/sentence_bert_config.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/config_sentence_transformers.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/model.safetensors\n",
      "/kaggle/input/some-pack/sentence-transformer-model/modules.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/special_tokens_map.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/vocab.txt\n",
      "/kaggle/input/some-pack/sentence-transformer-model/1_Pooling/config.json\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/certifi-2024.12.14-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/tqdm-4.67.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/sentence_transformers-3.3.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/jinja2-3.1.4-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/idna-3.10-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/mpmath-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/fsspec-2024.10.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/networkx-3.4.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/transformers-4.47.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/filelock-3.16.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/numpy-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/requests-2.32.3-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/joblib-1.4.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/urllib3-2.2.3-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/typing_extensions-4.12.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/sympy-1.13.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/huggingface_hub-0.26.5-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/packaging-24.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/spm.model\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/config.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/tokenizer.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/tokenizer_config.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/model.safetensors\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/special_tokens_map.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/added_tokens.json\n",
      "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
      "/kaggle/input/llm-classification-finetuning/train.csv\n",
      "/kaggle/input/llm-classification-finetuning/test.csv\n",
      "/kaggle/input/lmsys-wheel-files/peft-0.11.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/transformers-4.42.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/sympy-1.12.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/urllib3-2.2.2-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/tqdm-4.66.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/idna-3.7-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/jinja2-3.1.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/mpmath-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/networkx-3.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/filelock-3.15.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/certifi-2024.7.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/accelerate-0.32.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/packaging-24.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/requests-2.32.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/typing_extensions-4.12.2-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/huggingface_hub-0.23.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/fsspec-2024.6.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/.ipynb_checkpoints/dataset-metadata-checkpoint.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/tokenizer.model\n",
      "/kaggle/input/akemiiiiii/balanced_transformed_dataset.csv\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/spm.model\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/custom_model_complete.pth\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/tokenizer.json\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/tokenizer_config.json\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/model_config.pth\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/special_tokens_map.json\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/custom_model_weights.pth\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/added_tokens.json\n",
      "/kaggle/input/pppppppp/final_model_dir/config.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/spm.model\n",
      "/kaggle/input/pppppppp/merged_model_dir/config.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/tokenizer.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/tokenizer_config.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/custom_model.pth\n",
      "/kaggle/input/pppppppp/merged_model_dir/special_tokens_map.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc423ba",
   "metadata": {
    "papermill": {
     "duration": 0.004208,
     "end_time": "2025-07-28T07:56:44.034463",
     "exception": false,
     "start_time": "2025-07-28T07:56:44.030255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a7b526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:56:44.044703Z",
     "iopub.status.busy": "2025-07-28T07:56:44.044458Z",
     "iopub.status.idle": "2025-07-28T07:56:44.050509Z",
     "shell.execute_reply": "2025-07-28T07:56:44.049567Z"
    },
    "papermill": {
     "duration": 0.013312,
     "end_time": "2025-07-28T07:56:44.052297",
     "exception": false,
     "start_time": "2025-07-28T07:56:44.038985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prepare_test_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare_test_file.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n",
    "df[\"winner_model_a\"] = 1\n",
    "df[\"winner_model_b\"] = 0\n",
    "df[\"winner_tie\"] = 0\n",
    "df.to_parquet(\"test.parquet\", index=False)\n",
    "\n",
    "df[\"response_a\"], df[\"response_b\"] = df[\"response_b\"], df[\"response_a\"]\n",
    "df.to_parquet(\"test_swap.parquet\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483c286e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:56:44.063814Z",
     "iopub.status.busy": "2025-07-28T07:56:44.063538Z",
     "iopub.status.idle": "2025-07-28T07:56:46.110903Z",
     "shell.execute_reply": "2025-07-28T07:56:46.109947Z"
    },
    "papermill": {
     "duration": 2.055759,
     "end_time": "2025-07-28T07:56:46.113262",
     "exception": false,
     "start_time": "2025-07-28T07:56:44.057503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python prepare_test_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de488e6",
   "metadata": {
    "papermill": {
     "duration": 0.005188,
     "end_time": "2025-07-28T07:56:46.123225",
     "exception": false,
     "start_time": "2025-07-28T07:56:46.118037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference: gemma2-9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056fc46f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:56:46.133472Z",
     "iopub.status.busy": "2025-07-28T07:56:46.133216Z",
     "iopub.status.idle": "2025-07-28T07:56:46.139510Z",
     "shell.execute_reply": "2025-07-28T07:56:46.138804Z"
    },
    "papermill": {
     "duration": 0.013537,
     "end_time": "2025-07-28T07:56:46.141191",
     "exception": false,
     "start_time": "2025-07-28T07:56:46.127654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m0.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_gemma2 import Gemma2ForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/lmsys-checkpoints-0-0805\"\n",
    "csv_path = \"test.parquet\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "processor = ProcessorPAB(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096,\n",
    "    support_system_role=False,\n",
    ")\n",
    "dataset = LMSYSDataset(\n",
    "    csv_file=csv_path,\n",
    "    query=None,\n",
    "    processor=processor,\n",
    "    include_swap=False,\n",
    "    is_parquet=True,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 42\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.head_dim\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "\n",
    "# for name, p in model.named_parameters():\n",
    "#     print(name, p.device)\n",
    "# for name, b in model.model.named_buffers():\n",
    "#     print(name, b.device)\n",
    "\n",
    "# pipeline parallelism with two GPUs\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save('prob_m0.npy', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a154c0d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T07:56:46.151129Z",
     "iopub.status.busy": "2025-07-28T07:56:46.150904Z",
     "iopub.status.idle": "2025-07-28T08:00:29.187032Z",
     "shell.execute_reply": "2025-07-28T08:00:29.185947Z"
    },
    "papermill": {
     "duration": 223.043664,
     "end_time": "2025-07-28T08:00:29.189296",
     "exception": false,
     "start_time": "2025-07-28T07:56:46.145632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [03:16<00:00, 49.08s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2025-07-28 08:00:12.571105: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-07-28 08:00:12.571252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-07-28 08:00:12.696377: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:14<00:00, 14.36s/it]\r\n",
      "{'log_loss': 3.094615495202658}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b9b70",
   "metadata": {
    "papermill": {
     "duration": 0.005207,
     "end_time": "2025-07-28T08:00:29.200009",
     "exception": false,
     "start_time": "2025-07-28T08:00:29.194802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference: llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99253c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:00:29.211796Z",
     "iopub.status.busy": "2025-07-28T08:00:29.211488Z",
     "iopub.status.idle": "2025-07-28T08:00:29.219056Z",
     "shell.execute_reply": "2025-07-28T08:00:29.218170Z"
    },
    "papermill": {
     "duration": 0.01553,
     "end_time": "2025-07-28T08:00:29.220648",
     "exception": false,
     "start_time": "2025-07-28T08:00:29.205118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m3.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_llama import LlamaForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/lmsys-checkpoints-3-0805\"\n",
    "csv_path = \"test_swap.parquet\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.deprecation_warnings[\n",
    "    \"sequence-length-is-longer-than-the-specified-maximum\"\n",
    "] = True\n",
    "processor = ProcessorPAB(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096,\n",
    "    support_system_role=True,\n",
    ")\n",
    "dataset = LMSYSDataset(\n",
    "    csv_file=csv_path,\n",
    "    query=None,\n",
    "    processor=processor,\n",
    "    include_swap=False,\n",
    "    is_parquet=True,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 32\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.hidden_size // config.num_attention_heads\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save('prob_m3.npy', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c2287c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:00:29.232097Z",
     "iopub.status.busy": "2025-07-28T08:00:29.231862Z",
     "iopub.status.idle": "2025-07-28T08:03:24.875653Z",
     "shell.execute_reply": "2025-07-28T08:03:24.874802Z"
    },
    "papermill": {
     "duration": 175.651864,
     "end_time": "2025-07-28T08:03:24.877798",
     "exception": false,
     "start_time": "2025-07-28T08:00:29.225934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [02:42<00:00, 40.52s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2025-07-28 08:03:16.496108: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-07-28 08:03:16.496182: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-07-28 08:03:16.497907: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.81s/it]\r\n",
      "{'log_loss': 0.7582519183970864}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf0918db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:03:24.890602Z",
     "iopub.status.busy": "2025-07-28T08:03:24.890350Z",
     "iopub.status.idle": "2025-07-28T08:03:24.896293Z",
     "shell.execute_reply": "2025-07-28T08:03:24.895592Z"
    },
    "papermill": {
     "duration": 0.014154,
     "end_time": "2025-07-28T08:03:24.897890",
     "exception": false,
     "start_time": "2025-07-28T08:03:24.883736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98613375 0.0021362  0.01173002]\n",
      " [0.13743691 0.5760938  0.28646934]\n",
      " [0.7586595  0.09096359 0.1503769 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "prob = np.load('prob_m3.npy')\n",
    "\n",
    "print(prob[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509755fc",
   "metadata": {
    "papermill": {
     "duration": 0.005771,
     "end_time": "2025-07-28T08:03:24.909441",
     "exception": false,
     "start_time": "2025-07-28T08:03:24.903670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8cb2cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:03:24.921515Z",
     "iopub.status.busy": "2025-07-28T08:03:24.921304Z",
     "iopub.status.idle": "2025-07-28T08:03:25.412711Z",
     "shell.execute_reply": "2025-07-28T08:03:25.411867Z"
    },
    "papermill": {
     "duration": 0.499452,
     "end_time": "2025-07-28T08:03:25.414503",
     "exception": false,
     "start_time": "2025-07-28T08:03:24.915051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  winner_model_a  winner_model_b  winner_tie\n",
      "0   136060        0.002253        0.981807    0.015940\n",
      "1   211333        0.527081        0.128636    0.344282\n",
      "2  1233961        0.085258        0.765311    0.149431\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"test.parquet\")\n",
    "\n",
    "\n",
    "prob_m0 = np.load(\"prob_m0.npy\")  # Gemma2\n",
    "prob_m3 = np.load(\"prob_m3.npy\")[:, [1, 0, 2]]  # Llama3 (swap response_a and response_b)\n",
    "\n",
    "# Combine predictions with weights\n",
    "# Adjust weights as needed for optimal performance\n",
    "preds = np.average(\n",
    "    [\n",
    "        prob_m0,       # Gemma2 results\n",
    "        prob_m3,       # Llama3 results\n",
    "    ],\n",
    "    axis=0,\n",
    "    weights=[0.57, 0.43]  # Weights for each model\n",
    ")\n",
    "\n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame({\n",
    "    \"id\": df[\"id\"],\n",
    "    \"winner_model_a\": preds[:, 0],\n",
    "    \"winner_model_b\": preds[:, 1],\n",
    "    \"winner_tie\": preds[:, 2],\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(sub.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "datasetId": 5297895,
     "sourceId": 8897601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5369301,
     "sourceId": 8926343,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5493674,
     "sourceId": 9102725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496762,
     "sourceId": 9107824,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496847,
     "sourceId": 9107963,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496920,
     "sourceId": 9108069,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6265978,
     "sourceId": 10150018,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6267026,
     "sourceId": 10214229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6266300,
     "sourceId": 10236316,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6265823,
     "sourceId": 10302322,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 86587,
     "modelInstanceId": 63082,
     "sourceId": 75103,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 501.446597,
   "end_time": "2025-07-28T08:03:25.737882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-28T07:55:04.291285",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
